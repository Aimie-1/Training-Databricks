{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1664923e-f118-474f-b346-9b72d502e4df",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Config"
    }
   },
   "outputs": [],
   "source": [
    "#define varibles use in the scripts\n",
    "catalog_name = \"capstone_aimie_dbk\"\n",
    "schema_name = \"medisure\"\n",
    "\n",
    "#storage path\n",
    "input_path = \"/Volumes/capstone_aimie_dbk/medisure/inputs\"\n",
    "schem_path = \"/Volumes/capstone_aimie_dbk/medisure/schem\"\n",
    "bronze_path = \"/Volumes/capstone_aimie_dbk/medisure/schem/bronze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f65b6a85-3c4f-4486-88ac-da9a6dfcac34",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Schema and Volume"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_name}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog_name}.{schema_name}.inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12e22dd7-87f9-4b73-adfe-b75c69c5f335",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Phase: CSVs to Bronze"
    }
   },
   "outputs": [],
   "source": [
    "#creation of Bronze tables \n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType, DateType, ArrayType, BooleanType\n",
    "\n",
    "# Define explicit schemas for enforcement\n",
    "claims_batch_schema = StructType([\n",
    "    StructField(\"ClaimID\", StringType(), True),\n",
    "    StructField(\"MemberID\", StringType(), True),\n",
    "    StructField(\"ProviderID\", StringType(), True),\n",
    "    StructField(\"ClaimDate\", StringType(), True),       \n",
    "    StructField(\"ServiceDate\", StringType(), True),    \n",
    "    StructField(\"Amount\", DoubleType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"ICD10Codes\", StringType(), True),       \n",
    "    StructField(\"CPTCodes\", StringType(), True),        \n",
    "    StructField(\"ClaimType\", StringType(), True),\n",
    "    StructField(\"SubmissionChannel\", StringType(), True),\n",
    "    StructField(\"Notes\", StringType(), True),\n",
    "    StructField(\"IngestTimestamp\", StringType(), True)   \n",
    "])\n",
    "\n",
    "claims_stream_schema = StructType([\n",
    "    StructField(\"ClaimID\", StringType(), True),\n",
    "    StructField(\"MemberID\", StringType(), True),\n",
    "    StructField(\"ProviderID\", StringType(), True),\n",
    "    StructField(\"ClaimDate\", StringType(), True),  \n",
    "    StructField(\"Amount\", DoubleType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"ICD10Codes\", StringType(), True), \n",
    "    StructField(\"CPTCodes\", StringType(), True),   \n",
    "    StructField(\"EventTimestamp\", StringType(), True)\n",
    "])\n",
    "\n",
    "diagnosis_schema = StructType([\n",
    "    StructField(\"Code\", StringType(), True),\n",
    "    StructField(\"Description\", StringType(), True)\n",
    "])\n",
    "\n",
    "members_schema = StructType([\n",
    "    StructField(\"MemberID\", StringType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"DOB\", StringType(), True),               \n",
    "    StructField(\"Gender\", StringType(), True),\n",
    "    StructField(\"Region\", StringType(), True),\n",
    "    StructField(\"PlanType\", StringType(), True),\n",
    "    StructField(\"EffectiveDate\", StringType(), True),     \n",
    "    StructField(\"Email\", StringType(), True),\n",
    "    StructField(\"IsActive\", DoubleType(), True),         \n",
    "    StructField(\"LastUpdated\", StringType(), True)      \n",
    "])\n",
    "\n",
    "providers_schema = StructType([\n",
    "    StructField(\"ProviderID\", StringType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Specialties\", ArrayType(StringType()), True),\n",
    "    StructField(\"Locations\", ArrayType(StructType([\n",
    "        StructField(\"Address\", StringType(), True),\n",
    "        StructField(\"City\", StringType(), True),\n",
    "        StructField(\"State\", StringType(), True)\n",
    "    ])), True),\n",
    "    StructField(\"IsActive\", BooleanType(), True),\n",
    "    StructField(\"TIN\", StringType(), True),\n",
    "    StructField(\"LastVerified\", DateType(), True)\n",
    "])\n",
    "\n",
    "bronze_claims_batch_df = (spark.read\n",
    "            .format(\"csv\")\n",
    "            .schema(claims_batch_schema)\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"timestampFormat\", \"yyyy-MM-dd[ HH:mm:ss]\")\n",
    "            .load(f\"{input_path}/claims_batch.csv\"))\n",
    "\n",
    "bronze_claims_stream_df = (spark.read\n",
    "                    .schema(claims_stream_schema)\n",
    "                    .json(f\"{input_path}/claims_stream.json\"))\n",
    "\n",
    "bronze_diagnosis_df = (spark.read\n",
    "               .format(\"csv\")\n",
    "               .schema(diagnosis_schema)\n",
    "               .option(\"header\", \"true\")\n",
    "               .load(f\"{input_path}/diagnosis_ref.csv\"))\n",
    "\n",
    "bronze_members_df = (spark.read\n",
    "                .format(\"csv\")\n",
    "                .schema(members_schema)\n",
    "                .option(\"header\", \"true\")\n",
    "                .load(f\"{input_path}/members.csv\"))\n",
    "\n",
    "bronze_providers_df = (spark.read\n",
    "                    .schema(providers_schema)\n",
    "                    .json(f\"{input_path}/providers.json\"))\n",
    "\n",
    "(bronze_claims_batch_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"medisure.bronze_claims_batch\"))\n",
    "(bronze_claims_stream_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"medisure.bronze_claims_stream\"))\n",
    "(bronze_diagnosis_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"medisure.bronze_diagnosis_ref\"))\n",
    "(bronze_members_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"medisure.bronze_members\"))\n",
    "(bronze_providers_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"medisure.bronze_providers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09e86aa8-e7bb-4d84-a44e-b9d8a3c2dc82",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Phase: Bronze to Silver"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "silver_claims_batch_df = (\n",
    "    bronze_claims_batch_df\n",
    "    .withColumn( \"ClaimDate\",col(\"ClaimDate\").cast(\"date\"))\n",
    "    .withColumn( \"ServiceDate\",col(\"ServiceDate\").cast(\"date\"))\n",
    "    .withColumn( \"IngestTimestamp\",col(\"IngestTimestamp\").cast(\"timestamp\"))\n",
    ").dropna(subset=[\"ClaimID\", \"MemberID\", \"ProviderID\"]).dropDuplicates([\"ClaimID\", \"MemberID\", \"ProviderID\"]).filter((col(\"ClaimID\").isNotNull()) & (col(\"MemberID\").isNotNull()) & (col(\"ProviderID\").isNotNull()))\n",
    "\n",
    "silver_claims_stream_df = (\n",
    "    bronze_claims_stream_df\n",
    "    .withColumn( \"ClaimDate\",col(\"ClaimDate\").cast(\"date\"))\n",
    "    .withColumn( \"EventTimestamp\",col(\"EventTimestamp\").cast(\"timestamp\"))\n",
    ").dropna(subset=[\"ClaimID\", \"MemberID\", \"ProviderID\"]).dropDuplicates([\"ClaimID\", \"MemberID\", \"ProviderID\"]).filter((col(\"ClaimID\").isNotNull()) & (col(\"MemberID\").isNotNull()) & (col(\"ProviderID\").isNotNull()))\n",
    "\n",
    "silver_diagnosis_df = (\n",
    "    bronze_diagnosis_df\n",
    ").dropna(subset=[\"Code\"]).dropDuplicates([\"Code\"]).filter((col(\"Code\").isNotNull()) & (col(\"Description\").isNotNull()))\n",
    "\n",
    "silver_members_df = (\n",
    "    bronze_members_df\n",
    "    .withColumn( \"DOB\",col(\"DOB\").cast(\"date\"))\n",
    "    .withColumn( \"EffectiveDate\",col(\"EffectiveDate\").cast(\"date\"))\n",
    "    .withColumn( \"LastUpdated\",col(\"LastUpdated\").cast(\"date\"))\n",
    ").dropna(subset=[\"MemberID\"]).dropDuplicates([\"MemberID\"]).filter((col(\"MemberID\").isNotNull()))\n",
    "\n",
    "silver_providers_df = (\n",
    "    bronze_providers_df\n",
    "    .withColumn( \"LastVerified\",col(\"LastVerified\").cast(\"date\"))\n",
    ").dropna(subset=[\"ProviderID\"]).dropDuplicates([\"ProviderID\"]).filter((col(\"ProviderID\").isNotNull()))\n",
    "\n",
    "(silver_claims_batch_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"medisure.silver_claims_batch\"))\n",
    "(silver_claims_stream_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"medisure.silver_claims_stream\"))\n",
    "(silver_diagnosis_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"medisure.silver_diagnosis_ref\"))\n",
    "(silver_members_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"medisure.silver_members\"))\n",
    "(silver_providers_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"medisure.silver_providers\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9ee6a02-e490-4516-9dc6-9a733a936355",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756496675001}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_providers_df.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Ingestions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
